{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44df83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import obspy\n",
    "from obspy.clients.fdsn import Client\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from obspy import UTCDateTime\n",
    "from dateutil import parser\n",
    "from pytz import timezone\n",
    "import obspy\n",
    "from obspy.clients.fdsn.mass_downloader import CircularDomain, \\\n",
    "    Restrictions, MassDownloader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# importing the dependencies. \n",
    "\n",
    "import scipy as sc\n",
    "from scipy import signal\n",
    "import h5py\n",
    "\n",
    "from obspy.signal.filter import envelope\n",
    "\n",
    "import tsfel\n",
    "import random\n",
    "from datetime import timedelta\n",
    "import calendar\n",
    "from tsfel import time_series_features_extractor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "#%config InlineBackend.figure_format = \"png\"\n",
    "\n",
    "#from Feature_Extraction import compute_hibert\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# displaying all columns from pandas dataframe\n",
    "# Set display options to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/ak287/PNW_ML_Classification/notebooks/')\n",
    "\n",
    "import seis_feature\n",
    "\n",
    "\n",
    "sys.path.append('/home/ak287/Data_Mining_in_the_PNW/Common_Scripts/')\n",
    "from common_processing_functions import apply_cosine_taper\n",
    "from common_processing_functions import butterworth_filter\n",
    "\n",
    "import json\n",
    "\n",
    "from zenodo_get import zenodo_get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d29dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e67559e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884b6355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb7dce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899d687e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088291a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d0dfe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edc0855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec1af383",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cfg_file_sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3295942/4052247181.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Save the dictionary to a JSON file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_file_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cfg_file_sample' is not defined"
     ]
    }
   ],
   "source": [
    "## Loading the configuration file that contains features we want to extract. \n",
    "\n",
    "\n",
    "# Specify the file path where you want to save the JSON file\n",
    "file_path = '../Common_Scripts/cfg_file_sample.json'\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(cfg_file_sample, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc43ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b41dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc80aaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the common dataset on which the model was trained so I can grab its columns. \n",
    "common_dataset = pd.read_csv('../Results/common_train_dataset_reduced.csv')\n",
    "\n",
    "# grabbing the columns of common dataset. \n",
    "columns = common_dataset.columns[1:]\n",
    "\n",
    "\n",
    "# Later, you can load the model from disk\n",
    "loaded_model = load('../Results/best_rf_model_top_50_features_50_100.joblib')\n",
    "\n",
    "# Loading the standard scaler parameters to standardize the features in the same way as training dataset. \n",
    "scaler_params = pd.read_csv('/home/ak287/PNW_ML_Classification/results/params_standard_scaler_rf.csv')\n",
    "scaler_params.index = scaler_params['Feature']\n",
    "#columns = scaler_params['Feature'].values\n",
    "\n",
    "\n",
    "\n",
    "# These are the parameters of bandpass filter function. \n",
    "lowcut = 1\n",
    "highcut = 10\n",
    "fs = 100\n",
    "num_corners = 4\n",
    "\n",
    "\n",
    "## Number of CPUs to use. \n",
    "num_cpus = 48\n",
    "\n",
    "\n",
    "client = Client(\"IRIS\")\n",
    "\n",
    "\n",
    "## Stations on which we want to run the detector\n",
    "stations_id = ['UW.RCM','UW.STAR', 'CC.OBSR']\n",
    "\n",
    "\n",
    "\n",
    "# starttime from where we want to run the detector\n",
    "starttime = obspy.UTCDateTime(2020, 4, 9, 13, 28, 30) -  300\n",
    "\n",
    "\n",
    "# duration (in seconds) for which we want to run our detector\n",
    "dur = 1800\n",
    "\n",
    "\n",
    "# sampling frequency\n",
    "samp_freq = 100\n",
    "\n",
    "# input window length \n",
    "win = 150\n",
    "\n",
    "# stride for the detector (time x freq)\n",
    "stride = 30*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3b6782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9698976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f328b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st_data_full = []\n",
    "result_stns = []\n",
    "index_stns = []\n",
    "prob_stns = []\n",
    "\n",
    "st_overall = []\n",
    "st_overall_data = []\n",
    "st_overall_times = []\n",
    "\n",
    "\n",
    "\n",
    "for stn_id in tqdm(stations_id):\n",
    "    \n",
    "    \n",
    "    ## Extracting the station\n",
    "    stn = stn_id.split('.')[1]\n",
    "    \n",
    "    ## Extracting the network\n",
    "    network = stn_id.split('.')[0]\n",
    "        \n",
    "\n",
    "    \n",
    "    st = []\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Attempt to get waveform using 'EHZ' channel\n",
    "        st = client.get_waveforms(starttime=starttime, endtime=starttime + dur, station=stn,\n",
    "                                  network=network, channel='EHZ', location=location)\n",
    "    except:\n",
    "        try:\n",
    "            # Attempt to get waveform using 'BHZ' channel\n",
    "            st = client.get_waveforms(starttime=starttime, endtime=starttime + dur, station=stn,\n",
    "                                      network=network, channel='BHZ', location=location)\n",
    "        except:\n",
    "            try:\n",
    "                # Use 'HHZ' channel as a fallback option\n",
    "                st = client.get_waveforms(starttime=starttime, endtime=starttime + dur, station=stn,\n",
    "                                          network=network, channel='HHZ', location=location)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        # resampling all the data to 100 Hz since thats \n",
    "        st = st.resample(samp_freq) \n",
    "\n",
    "        st.detrend()\n",
    "\n",
    "        st_data_full = []\n",
    "        \n",
    "        ## Ideally the data should come in single stream (len(st) == 1) but if it comes in multiple streams\n",
    "        ## We will take the first stream. \n",
    "        times = st[0].times()\n",
    "        for i in range(len(st)):\n",
    "            st_data_full = np.hstack([st_data_full, st[i].data])\n",
    "        \n",
    "        \n",
    "            if i+1 < len(st):\n",
    "                diff = st[i+1].stats.starttime - st[i].stats.endtime\n",
    "\n",
    "                \n",
    "                print(np.hstack((st[i+1].times()+times[-1],  times)))\n",
    "                times = np.hstack((times, st[i+1].times()+times[-1]+diff))\n",
    "               \n",
    "                \n",
    "                \n",
    "                \n",
    "                #print('Final times')\n",
    "             \n",
    "\n",
    "        st_overall_data.append(st_data_full)\n",
    "        st_overall.append(st)\n",
    "        st_overall_times.append(times)\n",
    "        trace_data = [st_data_full[i:i+int(win*samp_freq)] for i in tqdm(range(0, len(st_data_full), stride)) if len(st_data_full[i:i+int(win*samp_freq)]) == int(win*samp_freq)]\n",
    "        trace_times = [times[i] for i in tqdm(range(0, len(st_data_full), stride)) if len(st_data_full[i:i+int(win*samp_freq)]) == int(win*samp_freq)]\n",
    "\n",
    "\n",
    "\n",
    "        trace_data = np.array(trace_data)\n",
    "        tapered = apply_cosine_taper(trace_data)\n",
    "        filtered = butterworth_filter(tapered, lowcut, highcut, fs, num_corners, filter_type='bandpass')\n",
    "\n",
    "        # Applying the normalization.\n",
    "        norm = filtered / np.max(abs(np.stack(filtered)), axis=1)[:, np.newaxis]\n",
    "\n",
    "        result = []\n",
    "        prob = []\n",
    "        time = []\n",
    "        index = []\n",
    "\n",
    "        for i in tqdm(range(len(norm))):\n",
    "\n",
    "\n",
    "            tsfel_features = time_series_features_extractor(cfg_file_sample, norm[i], fs=100)\n",
    "            tr_full = obspy.Trace(norm[i])\n",
    "            tr_full.stats.sampling_rate = 100\n",
    "            physical_features = seis_feature.compute_physical_features(tr=tr_full, envfilter=False)\n",
    "\n",
    "            final_features = pd.concat([tsfel_features, physical_features], axis=1)\n",
    "            final_features['hod'] = (starttime).hour - 8\n",
    "            final_features['dow'] = (starttime).weekday\n",
    "            final_features['moy'] = (starttime).month\n",
    "\n",
    "            features = final_features.loc[:, columns]\n",
    "\n",
    "            final_scaler_params = scaler_params.loc[features.columns]\n",
    "\n",
    "            for k in range(len(features.columns)):\n",
    "                features.iloc[:, k] = (features.iloc[:, k] - final_scaler_params.iloc[k, 2]) / final_scaler_params.iloc[k, 3]\n",
    "\n",
    "            # Check for NaN values in features\n",
    "            if features.isnull().values.any():\n",
    "                print(f\"NaN values detected in iteration {i}. Skipping prediction.\")\n",
    "\n",
    "            #features['E_20_50'] = 0.001\n",
    "            # extracting the results.\n",
    "            result.append(loaded_model.predict(features))\n",
    "            prob.append(loaded_model.predict_proba(features))\n",
    "            index.append(i)\n",
    "\n",
    "\n",
    "        result_stns.append(result)\n",
    "        index_stns.append(index)\n",
    "        prob_stns.append(prob)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0707d60b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ef4ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4ea2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2984fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d382b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d050d24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af62b3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b2f818",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.labelsize'] = 16  # Font size for xtick labels\n",
    "plt.rcParams['ytick.labelsize'] = 20  # Font size for ytick labels\n",
    "\n",
    "fig, axs = plt.subplots(len(st_overall_data), 1, figsize=(15, 3*len(st_overall_data)))\n",
    "\n",
    "for k in range(len(st_overall_data)):\n",
    "    \n",
    "    ## This is plotting the normalized data\n",
    "    axs[k].plot(st_overall_times[k], st_overall_data[k] / np.max(abs(st_overall_data[k])))\n",
    "    \n",
    "    ## Setting the title of the plot\n",
    "    axs[k].set_title(st_overall[k][0].id, fontsize=20)\n",
    "    \n",
    "    ## These are the colors of detection window. \n",
    "    colors = ['black', 'blue', 'gray', 'red']\n",
    "    for i in range(len(index_stns[k])):\n",
    "        axs[k].axvline(30 * index_stns[k][i] + 75, ls='--', color=colors[int(result_stns[k][i])], alpha = 0.6)\n",
    "    axs[k].scatter(30 * np.array(index_stns[k]) + 75, np.array(prob_stns[k])[:, :, 3], ec='k', marker='o', c='yellow', s=50, label='Prob (Su)')\n",
    "    axs[k].legend()\n",
    "    axs[k].set_xlabel('Time(s) since ' + str(starttime).split('.')[0], fontsize=20)\n",
    "    # axs[k].set_xlim(300, 1000)  # Set x-axis limits if needed\n",
    "\n",
    "plt.tight_layout()  # Adjust subplots to avoid overlap\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28979bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c381b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.labelsize'] = 16  # Font size for xtick labels\n",
    "plt.rcParams['ytick.labelsize'] = 20  # Font size for ytick labels\n",
    "\n",
    "fig, axs = plt.subplots(len(st_overall_data), 1, figsize=(15, 3*len(st_overall_data)))\n",
    "\n",
    "for k in range(len(st_overall_data)):\n",
    "    \n",
    "    ## This is plotting the normalized data\n",
    "    axs[k].plot(st_overall_times[k], st_overall_data[k] / np.max(abs(st_overall_data[k])), zorder=1)\n",
    "    \n",
    "    ## Setting the title of the plot\n",
    "    axs[k].set_title(st_overall[k][0].id, fontsize=20)\n",
    "    \n",
    "    ## These are the colors of detection window. \n",
    "    colors = ['green', 'blue', 'gray', 'red']\n",
    "    for i in range(len(index_stns[k])):\n",
    "        axs[k].axvline(30 * index_stns[k][i] + 75, ls='--', color=colors[int(result_stns[k][i])], alpha = 0.6)\n",
    "    axs[k].scatter(30 * np.array(index_stns[k]) + 75, np.array(prob_stns[k])[:, :, 3], ec='k', marker='o', c='yellow', s=50, label='Prob (Su)', zorder=2)\n",
    "    axs[k].legend()\n",
    "    \n",
    "    \n",
    "plt.xlabel('Time(s) since ' + str(starttime).split('.')[0], fontsize=20)\n",
    "    # axs[k].set_xlim(300, 1000)  # Set x-axis limits if needed\n",
    "\n",
    "plt.tight_layout()  # Adjust subplots to avoid overlap\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeefa96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb64082f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc3c2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed84a3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.labelsize'] = 16  # Font size for xtick labels\n",
    "plt.rcParams['ytick.labelsize'] = 20  # Font size for ytick labels\n",
    "\n",
    "fig, axs = plt.subplots(len(st_overall_data), 1, figsize=(15, 3*len(st_overall_data)))\n",
    "\n",
    "for k in range(len(st_overall_data)):\n",
    "    axs[k].plot(st_overall_times[k], st_overall_data[k] / np.max(abs(st_overall_data[k])), color='blue', alpha=0.7)\n",
    "    axs[k].set_title(st_overall[k][0].id, fontsize=20)\n",
    "    colors = ['black', 'blue', 'green', 'red']\n",
    "    for i in range(len(index_stns[k])):\n",
    "        axs[k].axvline(30 * index_stns[k][i] + 75, ls='--', color=colors[int(result_stns[k][i])], alpha=0.5)\n",
    "    axs[k].scatter(30 * np.array(index_stns[k]) + 75, np.array(prob_stns[k])[:, :, 3], ec='k', marker='*', c='yellow', s=200, label='Prob (Su)', alpha=0.7)\n",
    "    axs[k].legend(fontsize=12, loc='upper right')\n",
    "    axs[k].set_xlabel('Time (s) since ' + str(starttime).split('.')[0], fontsize=16)\n",
    "    axs[k].set_ylabel('Normalized Amplitude', fontsize=16)\n",
    "    axs[k].grid(True, linestyle='--', alpha=0.5)  # Add gridlines with transparency\n",
    "\n",
    "plt.tight_layout()  # Adjust subplots to avoid overlap\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317cbd52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0305df20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.labelsize'] = 16  # Font size for xtick labels\n",
    "plt.rcParams['ytick.labelsize'] = 20  # Font size for ytick labels\n",
    "\n",
    "fig, axs = plt.subplots(len(st_overall_data), 1, figsize=(15, 3*len(st_overall_data)))\n",
    "\n",
    "for k in range(len(st_overall_data)):\n",
    "    axs[k].plot(st_overall_times[k], st_overall_data[k] / np.max(abs(st_overall_data[k])))\n",
    "    axs[k].set_title(st_overall[k][0].id, fontsize=20)\n",
    "    colors = ['black', 'blue', 'green', 'red']\n",
    "    #for i in range(len(index_stns[k])):\n",
    "        #axs[k].axvline(30 * index_stns[k][i] + 75, ls='--', color=colors[int(result_stns[k][i])])\n",
    "    axs[k].scatter(30 * np.array(index_stns[k]) + 75, np.array(prob_stns[k])[:, :, 3], ec='k', marker='*', c='yellow', s=200, label='Prob (Su)')\n",
    "    axs[k].legend()\n",
    "    axs[k].set_xlabel('Time(s) since ' + str(starttime).split('.')[0], fontsize=20)\n",
    "    axs[k].axvspan(300, 373, color='gray', alpha=0.5)  # Add a lightly shaded box between 300 and 700 seconds\n",
    "\n",
    "plt.tight_layout()  # Adjust subplots to avoid overlap\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011231dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af96e9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.labelsize'] = 16  # Font size for xtick labels\n",
    "plt.rcParams['ytick.labelsize'] = 20  # Font size for ytick labels\n",
    "\n",
    "fig, axs = plt.subplots(len(st_overall_data), 1, figsize=(15, 3*len(st_overall_data)))\n",
    "\n",
    "for k in range(len(st_overall_data)):\n",
    "    axs[k].plot(st_overall_times[k], st_overall_data[k] / np.max(abs(st_overall_data[k])))\n",
    "    axs[k].set_title(st_overall[k][0].id, fontsize=20)\n",
    "    colors = ['black', 'blue', 'green', 'red']\n",
    "    colors = ['black', 'blue', 'gray', 'red']\n",
    "    for i in range(len(index_stns[k])):\n",
    "        axs[k].axvline(30 * index_stns[k][i] + 75, ls='--', color=colors[int(result_stns[k][i])], alpha = 0.3)\n",
    "    \n",
    "    for i in range(len(index_stns[k])):\n",
    "        if result_stns[k][i] == 3:\n",
    "            axs[k].scatter(30 * index_stns[k][i] + 75, prob_stns[k][i][0][3], ec='k', marker='*', c='yellow', s=200)\n",
    "        else:\n",
    "            axs[k].scatter(30 * index_stns[k][i] + 75, prob_stns[k][i][0][3], ec='k', marker='*', c='white', s=0)\n",
    "    axs[k].legend()\n",
    "    axs[k].set_xlabel('Time(s) since ' + str(starttime).split('.')[0], fontsize=20)\n",
    "    axs[k].axvspan(300, 373, color='gray', alpha=0.5)  # Add a lightly shaded box between 300 and 373 seconds\n",
    "\n",
    "plt.tight_layout()  # Adjust subplots to avoid overlap\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b64a113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b621447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44de9597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bbe119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edff658c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b796d398",
   "metadata": {},
   "outputs": [],
   "source": [
    "st  = st_overall[0]\n",
    "## Ideally the data should come in single stream (len(st) == 1) but if it comes in multiple streams\n",
    "## We will take the first stream. \n",
    "times = st[0].times()\n",
    "for i in range(len(st)):\n",
    "    st_data_full = np.hstack([st_data_full, st[i].data])\n",
    "\n",
    "\n",
    "    if i+1 < len(st):\n",
    "        diff = st[i+1].stats.starttime - st[i].stats.endtime\n",
    "\n",
    "\n",
    "        #print(np.hstack((st[i+1].times()+times[-1],  times)))\n",
    "        \n",
    "        \n",
    "        times = np.hstack((times, st[i+1].times()+times[-1]+diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11e4fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108f81c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "st[2].times()+times[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8250f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roses_2021",
   "language": "python",
   "name": "roses_2021"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
